RAG Chatbot with Voice Recognition

*******Description: ************
This project is a local Retrieval-Augmented Generation (RAG) chatbot built with LangChain and Ollama (Mistral model). Users can ask questions about uploaded PDF documents and receive context-aware answers in real time.

*******The chatbot includes:*****

Voice recognition: Users can ask questions verbally using speech_recognition and PyAudio.

Intelligent retrieval: PDF documents are split into chunks and vectorized with FastEmbed for accurate context-based search.

Simple web interface: Built with Streamlit, with the text input and voice button aligned on the same line.

Question history: (optional) allows storing and displaying previous questions and answers.

******Technologies :***********

Python 3.x
Streamlit  # for the web interface
LangChain  # for the RAG pipeline
Ollama     # with Mistral model
PyPDF2     # for PDF text extraction
FastEmbed  # for local embeddings
FAISS      # for vector search
SpeechRecognition # and PyAudio for voice input

*******Key Features : *********

Upload multiple PDF files.

Automatic chunking of text for optimal processing.

Local embeddings and context-aware retrieval with FAISS.

Ask questions via keyboard or microphone.

Get concise, accurate answers generated by the Mistral model via Ollama.


# Install dependencies:

pip install -r requirements.txt

# Run Streamlit:

streamlit run app.py


# Upload PDFs and start asking questions.

*********Example Use Case: ************

Upload PDFs containing financial regulations.

Ask a question like: "What are the applicable interest rates for mortgage loans?".

The chatbot returns an answer based solely on the PDF content.

Notes:

Ensure your microphone works for voice recognition.

Ollama must be installed locally and the Mistral model downloaded.

If you want, I can also create a short, catchy version for the top of your README that grabs attention immediately.

Do you want me to do that?
